{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59ae6583-e912-4190-a958-76c456e76b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import tqdm\n",
    "import pathlib\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow_docs.vis import embed\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import imageio\n",
    "\n",
    "from IPython import display\n",
    "from urllib import request\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "618fb4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load videos \n",
    "\n",
    "dataset = []\n",
    "video_filenames = []\n",
    "\n",
    "for fn in glob.glob(\"../Videos/*\"):\n",
    "    video_filenames.append(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "093955cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for filename in video_filenames:\n",
    "#    with open(f\"../Annotations/{filename[10:-4]}.csv\", \"w\") as f:\n",
    "#        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c15a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Annotationben a táblák nevei\n",
    "class_names = [\"timestamp\", \"20\",\"30\",\"50\",\"60\",\"70\",\"80\",\n",
    "               \"sebKorlatVege\",\"100\",\"120\",\"elozniTilos\",\n",
    "               \"teherautovalElozniTilos\",\"keresztezodesAlarendeltUttal\",\n",
    "               \"foutvonal\",\"elsobbsegadas\",\"stop\",\"mind2BehajtaniTilos\",\n",
    "               \"teherautovalBehajtaniTilos\",\"behajtaniTilos\",\n",
    "               \"veszely\",\"veszelyesKanyarBal\",\"veszelyesKanyarJobb\",\n",
    "               \"veszelyesKanyarok\",\"egyenetlenUttsest\",\"csuszos\",\"utszukuletJobbrol\",\n",
    "               \"munka\",\"fenyjelzoKeszulek\",\"gyalogosAtkeles\",\"gyerekek\",\n",
    "               \"kerekparosok\",\"?\",\"vadVeszely\",\"korlatozasVege\",\n",
    "               \"kotelezoHaladasiIranyJobbra\",\"kotelezoHaladasiIranyBalra\",\n",
    "               \"kotelezoHaladasiIrany\",\"kotelezoHaladasiIranyJobbraEgyenesen\",\n",
    "               \"kotelezoHaladasiIranyBalraEgyenesen\",\"kerulesiIranyJobbra\",\n",
    "               \"kerulesiIranyBalra\",\"korforgalom\",\"elozniTilosVege\",\n",
    "               \"teherautovalElozniTilosVege\",\"40\",\"autopalya\",\"autopalyaVege\",\n",
    "               \"autout\",\"autoutVege\",\"buszmegallo\",\"egyiranyu\",\"foutVege\",\n",
    "               \"gyalogosAtkelo\",\"korforgalomPiros\",\"parkolo\",\n",
    "               \"szembejovoForgalomnakElsobbseg\",\"szembejovoForgalommalSzembenElsobbseg\",\n",
    "               \"utszukulet\",\"utszukuletBalrol\",\"veszelyesKanyarok2\",\"zsakutca\",\n",
    "               \"gyalogosok\",\"varakozniTilos\",\"megallniTilos\",\"jobbraKanyarodniTilos\",\n",
    "               \"balraKanyarodniTilos\",\"behajtaniTilosMegjeloltDolgokkal\",\n",
    "               \"behajtaniTilosKerekparral\",\"kerulesiIranyBalVagyJobb\",\n",
    "               \"behajtaniTilosSulykorlat\",\"bukkano\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8b38fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Videókhoz csv fájl rendelése\n",
    "video_filenames = glob.glob(\"../Videos/*.mp4\")\n",
    "\n",
    "for filename in video_filenames:\n",
    "    base = os.path.basename(filename)\n",
    "    name = base[:-4]  # pl. 0001\n",
    "    csv_path = f\"../Annotations/{name}.csv\"\n",
    "    \n",
    "    # Ha már létezik egy oszlop, azt ne írja felül\n",
    "    if os.path.exists(csv_path):\n",
    "        df_existing = pd.read_csv(csv_path)\n",
    "        for col in class_names:\n",
    "            if col not in df_existing.columns:\n",
    "                df_existing[col] = 0\n",
    "        df_existing.to_csv(csv_path, index=False)\n",
    "    # Új oszlopot adunk hozzá\n",
    "    else:\n",
    "        df = pd.DataFrame(\n",
    "            data=np.zeros((1000, len(class_names)), dtype=int),\n",
    "            columns=class_names)\n",
    "        df[\"timestamp\"] = [x/2 for x in range(0, 1000)]\n",
    "        df.to_csv(csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f2bf021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df = pd.DataFrame(\\n    data=np.zeros((1000, len(class_names)), dtype=int),\\n    columns=class_names)\\ndf[\"timestamp\"] = [x/2 for x in range(0, 1000, 1)] # TODO: set to video max frame count * x\\n\\ndf\\n\\n#for filename in video_filenames:    \\n#    with open(f\"../Annotations/{filename[10:-4]}.csv\", \"w\") as f:\\n#        df.to_csv(f, index=False)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"df = pd.DataFrame(\n",
    "    data=np.zeros((1000, len(class_names)), dtype=int),\n",
    "    columns=class_names)\n",
    "df[\"timestamp\"] = [x/2 for x in range(0, 1000, 1)] # TODO: set to video max frame count * x\n",
    "\n",
    "df\n",
    "\n",
    "#for filename in video_filenames:    \n",
    "#    with open(f\"../Annotations/{filename[10:-4]}.csv\", \"w\") as f:\n",
    "#        df.to_csv(f, index=False)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6ae1eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for filename in video_filenames:\\n    src = cv2.VideoCapture(str(filename))  \\n    print(\"FPS per video:\", src.get(cv2.CAP_PROP_FPS ))\\n    print(\"Frame per video:\",src.get(cv2.CAP_PROP_FRAME_COUNT))\\n    print(\"bitrate:\",src.get(cv2.CAP_PROP_BITRATE)) \\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"for filename in video_filenames:\n",
    "    src = cv2.VideoCapture(str(filename))  \n",
    "    print(\"FPS per video:\", src.get(cv2.CAP_PROP_FPS ))\n",
    "    print(\"Frame per video:\",src.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(\"bitrate:\",src.get(cv2.CAP_PROP_BITRATE)) \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cbb961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def format_frames(frame, output_size):\n",
    "\n",
    "    # Pad and resize an image from a video.\n",
    "\n",
    "    # Args:\n",
    "    # frame: Image that needs to resized and padded. \n",
    "    #  output_size: Pixel size of the output frame image.\n",
    "\n",
    "   # Return:\n",
    "  #    Formatted frame with padding of specified output size.\n",
    " # \"\"\"\n",
    " # frame = tf.image.convert_image_dtype(frame, tf.float32)\n",
    "  #frame = tf.image.resize_with_pad(frame, *output_size)\n",
    "  #return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d44495",
   "metadata": {},
   "source": [
    "def frames_from_video_file(video_path, n_frames=None, output_size = (224,224), frame_step = 15):\n",
    "  \"\"\"\n",
    "    Creates frames from each video file present for each category.\n",
    "\n",
    "    Args:\n",
    "      video_path: File path to the video.\n",
    "      n_frames: Number of frames to be created per video file.\n",
    "      output_size: Pixel size of the output frame image.\n",
    "\n",
    "    Return:\n",
    "      An NumPy array of frames in the shape of (n_frames, height, width, channels).\n",
    "  \"\"\"\n",
    "  result = []\n",
    "  src = cv2.VideoCapture(str(video_path))  \n",
    "  \n",
    "  video_length = src.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "  \n",
    "  if not n_frames:\n",
    "    n_frames = 1 + (video_length - 1) // frame_step\n",
    "\n",
    "  need_length = 1 + (n_frames - 1) * frame_step\n",
    "\n",
    "  # if need_length > video_length:\n",
    "  #   start = 0\n",
    "  # else:\n",
    "  #   max_start = video_length - need_length\n",
    "  #   start = random.randint(0, max_start + 1)\n",
    "  \n",
    "  start = 0\n",
    "\n",
    "  src.set(cv2.CAP_PROP_POS_FRAMES, start)\n",
    "  \n",
    "  # ret is a boolean indicating whether read was successful, frame is the image itself\n",
    "  ret, frame = src.read()\n",
    "  result.append(format_frames(frame, output_size))\n",
    "\n",
    "  for _ in range(n_frames - 1):\n",
    "    for _ in range(frame_step):\n",
    "      ret, frame = src.read()\n",
    "    # ret, frame = src.read()\n",
    "    if ret:\n",
    "      frame = format_frames(frame, output_size)\n",
    "      result.append(frame)\n",
    "    else:\n",
    "      result.append(np.zeros_like(result[0]))\n",
    "      \n",
    "  src.release()\n",
    "  \n",
    "  result = np.array(result)[..., [2, 1, 0]]\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6318eeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_video = frames_from_video_file(video_filenames[5], n_frames = 100)\n",
    "#sample_video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c33bb306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def to_gif(images):\\n  converted_images = np.clip(images * 255, 0, 255).astype(np.uint8)\\n  imageio.mimsave('./animation.gif', converted_images, fps=10)\\n  return embed.embed_file('./animation.gif')\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def to_gif(images):\n",
    "  converted_images = np.clip(images * 255, 0, 255).astype(np.uint8)\n",
    "  imageio.mimsave('./animation.gif', converted_images, fps=10)\n",
    "  return embed.embed_file('./animation.gif')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11553cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_gif(sample_video)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf53841",
   "metadata": {},
   "source": [
    "class FrameGenerator:\n",
    "  def __init__(self, training = False):\n",
    "    \"\"\" Returns a set of frames with their associated label. \n",
    "\n",
    "      Args:\n",
    "        path: Video file paths.\n",
    "        n_frames: Number of frames. \n",
    "        training: Boolean to determine if training dataset is being created.\n",
    "    \"\"\"\n",
    "    self.training = training\n",
    "    \n",
    "    self.class_names = sorted(set(p.name for p in video_filenames.iterdir() if p.is_dir()))\n",
    "    self.class_ids_for_name = dict((name, idx) for idx, name in enumerate(self.class_names))\n",
    "\n",
    "  def __call__(self):\n",
    "\n",
    "    if self.training:\n",
    "      random.shuffle()\n",
    "\n",
    "    for path, name in pairs:\n",
    "      video_frames = frames_from_video_file(path) \n",
    "      label = self.class_ids_for_name[name] # Encode labels\n",
    "      yield video_frames, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af6bdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk, messagebox\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "VIDEO_DIR = \"../Videos\"\n",
    "CSV_DIR = \"../Annotations\"\n",
    "TIMESTEP = 0.5\n",
    "\n",
    "#Tábla nevek\n",
    "COLUMNS = [\"timestamp\", \"20\",\"30\",\"50\",\"60\",\"70\",\"80\",\n",
    "               \"sebKorlatVege\",\"100\",\"120\",\"elozniTilos\",\n",
    "               \"teherautovalElozniTilos\",\"keresztezodesAlarendeltUttal\",\n",
    "               \"foutvonal\",\"elsobbsegadas\",\"stop\",\"mind2BehajtaniTilos\",\n",
    "               \"teherautovalBehajtaniTilos\",\"behajtaniTilos\",\n",
    "               \"veszely\",\"veszelyesKanyarBal\",\"veszelyesKanyarJobb\",\n",
    "               \"veszelyesKanyarok\",\"egyenetlenUttsest\",\"csuszos\",\"utszukuletJobbrol\",\n",
    "               \"munka\",\"fenyjelzoKeszulek\",\"gyalogosAtkeles\",\"gyerekek\",\n",
    "               \"kerekparosok\",\"?\",\"vadVeszely\",\"korlatozasVege\",\n",
    "               \"kotelezoHaladasiIranyJobbra\",\"kotelezoHaladasiIranyBalra\",\n",
    "               \"kotelezoHaladasiIrany\",\"kotelezoHaladasiIranyJobbraEgyenesen\",\n",
    "               \"kotelezoHaladasiIranyBalraEgyenesen\",\"kerulesiIranyJobbra\",\n",
    "               \"kerulesiIranyBalra\",\"korforgalom\",\"elozniTilosVege\",\n",
    "               \"teherautovalElozniTilosVege\",\"40\",\"autopalya\",\"autopalyaVege\",\n",
    "               \"autout\",\"autoutVege\",\"buszmegallo\",\"egyiranyu\",\"foutVege\",\n",
    "               \"gyalogosAtkelo\",\"korforgalomPiros\",\"parkolo\",\n",
    "               \"szembejovoForgalomnakElsobbseg\",\"szembejovoForgalommalSzembenElsobbseg\",\n",
    "               \"utszukulet\",\"utszukuletBalrol\",\"veszelyesKanyarok\",\"zsakutca\",\n",
    "               \"gyalogosok\",\"varakozniTilos\",\"megallniTilos\",\"jobbraKanyarodniTilos\",\n",
    "               \"balraKanyarodniTilos\",\"behajtaniTilosMegjeloltDolgokkal\",\n",
    "               \"behajtaniTilosKerekparral\",\"kerulesiIranyBalVagyJobb\",\n",
    "               \"behajtaniTilosSulykorlat\",\"bukkano\"\n",
    "]\n",
    "\n",
    "class VideoAnnotator:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Közlekedési tábla annotáló\")\n",
    "\n",
    "        self.video_files = sorted(f for f in os.listdir(VIDEO_DIR) if f.endswith(\".mp4\"))\n",
    "        self.current_index = 242\n",
    "    \n",
    "\n",
    "        self.canvas = tk.Canvas(root, width=1280, height=720)\n",
    "        self.canvas.grid(row=0, column=0, columnspan=3)\n",
    "\n",
    "        self.var_dict = {name: tk.IntVar() for name in COLUMNS}\n",
    "        self.check_frame = tk.Frame(root)\n",
    "        self.check_frame.grid(row=1, column=0, columnspan=3)\n",
    "\n",
    "        for i, name in enumerate(COLUMNS):\n",
    "            cb = tk.Checkbutton(self.check_frame, text=name, variable=self.var_dict[name])\n",
    "            cb.grid(row=i//10, column=i%10, sticky='w')\n",
    "\n",
    "        self.time_label = tk.Label(root, text=\"Idő: 0.0s\")\n",
    "        self.time_label.grid(row=2, column=0)\n",
    "\n",
    "        self.prev_btn = tk.Button(root, text=\"<< Vissza\", command=self.prev_frame)\n",
    "        self.prev_btn.grid(row=2, column=1)\n",
    "\n",
    "        self.next_btn = tk.Button(root, text=\">> Előre\", command=self.next_frame)\n",
    "        self.next_btn.grid(row=2, column=2)\n",
    "\n",
    "        self.root.protocol(\"WM_DELETE_WINDOW\", self.on_closing)\n",
    "\n",
    "        self.load_video()\n",
    "\n",
    "    def load_video(self):\n",
    "        video_file = self.video_files[self.current_index]\n",
    "        self.cap = cv2.VideoCapture(os.path.join(VIDEO_DIR, video_file))\n",
    "        self.fps = self.cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "        csv_path = os.path.join(CSV_DIR, video_file.replace(\".mp4\", \".csv\"))\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "\n",
    "        self.frame_index = 0\n",
    "        self.update_frame()\n",
    "\n",
    "    def update_frame(self):\n",
    "        timestamp = self.df.iloc[self.frame_index]['timestamp']\n",
    "        self.time_label.config(text=f\"Idő: {timestamp:.1f}s\")\n",
    "        frame_number = int(timestamp * self.fps)\n",
    "        self.cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "        ret, frame = self.cap.read()\n",
    "        if ret:\n",
    "            frame = cv2.resize(frame, (1280, 720))\n",
    "            img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            imgtk = ImageTk.PhotoImage(image=img)\n",
    "            self.canvas.imgtk = imgtk\n",
    "            self.canvas.create_image(0, 0, anchor='nw', image=imgtk)\n",
    "\n",
    "        for name in COLUMNS:\n",
    "            self.var_dict[name].set(int(self.df.iloc[self.frame_index].get(name, 0)))\n",
    "\n",
    "    def save_frame(self):\n",
    "        for name in COLUMNS:\n",
    "            self.df.at[self.frame_index, name] = self.var_dict[name].get()\n",
    "\n",
    "    def next_frame(self):\n",
    "        self.save_frame()\n",
    "        if self.frame_index + 1 < len(self.df):\n",
    "            self.frame_index += 1\n",
    "            self.update_frame()\n",
    "        else:\n",
    "            self.save_csv()\n",
    "            messagebox.showinfo(\"Kész\", \"Elértél a videó végére.\")\n",
    "\n",
    "    def prev_frame(self):\n",
    "        self.save_frame()\n",
    "        if self.frame_index > 0:\n",
    "            self.frame_index -= 1\n",
    "            self.update_frame()\n",
    "\n",
    "    def save_csv(self):\n",
    "        video_file = self.video_files[self.current_index]\n",
    "        csv_path = os.path.join(CSV_DIR, video_file.replace(\".mp4\", \".csv\"))\n",
    "        self.df.to_csv(csv_path, index=False)\n",
    "\n",
    "    def on_closing(self):\n",
    "        self.save_frame()\n",
    "        self.save_csv()\n",
    "        self.root.destroy()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    root = tk.Tk()\n",
    "    app = VideoAnnotator(root)\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6cb63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Képkockák mentése kész.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"VIDEO_DIR = r\"D:\\Szakdolgozat\\kozlekedesi_tabla_felismero\\Videos\"\n",
    "OUTPUT_DIR = r\"D:\\Szakdolgozat\\kozlekedesi_tabla_felismero\\ExtractedFrames\"\n",
    "TIMESTEP = 0.5  # másodperc\n",
    "FRAMES_PER_STEP = 5  # ennyi frame minden 0.5 mp-n belül\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "video_files = [f for f in os.listdir(VIDEO_DIR) if f.endswith(\".mp4\")]\n",
    "\n",
    "for video_file in video_files:\n",
    "    video_path = os.path.join(VIDEO_DIR, video_file)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duration_sec = total_frames / fps\n",
    "\n",
    "    print(f\"Feldolgozás: {video_file} ({duration_sec:.1f} mp)\")\n",
    "\n",
    "    num_steps = int(duration_sec / TIMESTEP)\n",
    "\n",
    "    # csak azokat a sorokat tartjuk meg, ahol van legalább egy 1 az oszlopok között\n",
    "    df = df[df.drop(columns=['timestamp']).sum(axis=1) > 0]\n",
    "\n",
    "\n",
    "    for step in range(num_steps):\n",
    "        timestamp = step * TIMESTEP\n",
    "        center_frame = int(timestamp * fps)\n",
    "        offsets = np.linspace(-2, 2, FRAMES_PER_STEP).astype(int)  # pl. [-2, -1, 0, 1, 2]\n",
    "\n",
    "        for i, offset in enumerate(offsets):\n",
    "            frame_idx = center_frame + offset\n",
    "            if frame_idx < 0 or frame_idx >= total_frames:\n",
    "                continue\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "            ret, frame = cap.read()\n",
    "            if ret:\n",
    "                resized = cv2.resize(frame, (640, 360))\n",
    "                output_name = f\"{os.path.splitext(video_file)[0]}_{timestamp:.1f}_{i+1}.png\"\n",
    "                output_path = os.path.join(OUTPUT_DIR, output_name)\n",
    "                cv2.imwrite(output_path, resized)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "print(\"✅ Minden videó feldolgozva.\")\n",
    "\n",
    "\n",
    "VIDEO_DIR = r\"D:\\Szakdolgozat\\kozlekedesi_tabla_felismero\\Videos\"\n",
    "CSV_DIR = r\"D:\\Szakdolgozat\\kozlekedesi_tabla_felismero\\Annotations\"\n",
    "OUTPUT_DIR = r\"D:\\Szakdolgozat\\kozlekedesi_tabla_felismero\\ExtractedFrames\"\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(VIDEO_DIR):\n",
    "    if filename.endswith(\".mp4\"):\n",
    "        video_path = os.path.join(VIDEO_DIR, filename)\n",
    "        csv_path = os.path.join(CSV_DIR, filename.replace(\".mp4\", \".csv\"))\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        # csak azok a sorok kellenek, ahol legalább egy oszlopban 1 van (kivéve a timestamp)\n",
    "        df_filtered = df[df.drop(columns=['timestamp']).sum(axis=1) > 0]\n",
    "\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "        for idx, row in df_filtered.iterrows():\n",
    "            timestamp = row['timestamp']\n",
    "            frame_number = int(timestamp * fps)\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "            ret, frame = cap.read()\n",
    "            if ret:\n",
    "                out_name = f\"{filename[:-4]}_{timestamp:.1f}.jpg\"\n",
    "                out_path = os.path.join(OUTPUT_DIR, out_name)\n",
    "                cv2.imwrite(out_path, frame)\n",
    "\n",
    "        cap.release()\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "# --- Beállítások ---\n",
    "VIDEO_DIR = \"../Videos\"\n",
    "CSV_DIR = \"../Annotations\"\n",
    "OUTPUT_DIR = \"../ExtractedFrames\"\n",
    "IMAGE_SIZE = (512, 512)\n",
    "FRAMES_PER_TIMESTAMP = 3  # Képkockák száma fél másodpercenként\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Osztályok listája (timestamp nélkül)\n",
    "with open(os.path.join(CSV_DIR, os.listdir(CSV_DIR)[0]), 'r') as f:\n",
    "    header = f.readline().strip().split(',')\n",
    "\n",
    "COLUMNS = [col for col in header if col != 'timestamp']\n",
    "\n",
    "for video_file in sorted(os.listdir(VIDEO_DIR)):\n",
    "    if not video_file.endswith(\".mp4\"):\n",
    "        continue\n",
    "\n",
    "    base_name = os.path.splitext(video_file)[0]\n",
    "    video_path = os.path.join(VIDEO_DIR, video_file)\n",
    "    csv_path = os.path.join(CSV_DIR, f\"{base_name}.csv\")\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        timestamp = row['timestamp']\n",
    "        active_labels = [label for label in COLUMNS if row.get(label, 0) == 1]\n",
    "        if not active_labels:\n",
    "            continue\n",
    "\n",
    "        # Időbélyeg képkockaszámra\n",
    "        center_frame = int(timestamp * fps)\n",
    "        offsets = [-1, 0, 1]  # 3 frame: középső + 1 előtte + 1 utána\n",
    "\n",
    "        for offset in offsets:\n",
    "            frame_num = center_frame + offset\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                continue\n",
    "\n",
    "            resized = cv2.resize(frame, IMAGE_SIZE)\n",
    "\n",
    "            for label in active_labels:\n",
    "                label_dir = os.path.join(OUTPUT_DIR, label)\n",
    "                os.makedirs(label_dir, exist_ok=True)\n",
    "                filename = f\"{base_name}_{timestamp:.1f}_{frame_num}.jpg\"\n",
    "                path = os.path.join(label_dir, filename)\n",
    "                cv2.imwrite(path, resized)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "print(\"Képkockák mentése kész.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e73f268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11942 files belonging to 49 classes.\n",
      "Using 9554 files for training.\n",
      "Found 11942 files belonging to 49 classes.\n",
      "Using 2388 files for validation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (512, 512)\n",
    "\n",
    "dataset_dir = \"../ExtractedFrames\"\n",
    "\n",
    "train_ds = image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "val_ds = image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Normalizálás 0-1 közé\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1e7b441",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FrameGenerator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m fg \u001b[38;5;241m=\u001b[39m \u001b[43mFrameGenerator\u001b[49m(training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m frames, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(fg())\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mframes\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'FrameGenerator' is not defined"
     ]
    }
   ],
   "source": [
    "fg = FrameGenerator(training=True)\n",
    "\n",
    "frames, label = next(fg())\n",
    "\n",
    "print(f\"Shape: {frames.shape}\")\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f092efea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training set\n",
    "output_signature = (tf.TensorSpec(shape = (None, None, None, 3), dtype = tf.float32),\n",
    "                    tf.TensorSpec(shape = (), dtype = tf.int16))\n",
    "\n",
    "train_ds = tf.data.Dataset.from_generator(FrameGenerator(#  10, \n",
    "                                                         training=True),\n",
    "                                          output_signature = output_signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a28701c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the validation set\n",
    "val_ds = tf.data.Dataset.from_generator(FrameGenerator(training=False),\n",
    "                                        output_signature = output_signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35d6a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size = AUTOTUNE)\n",
    "val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size = AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9154c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shapes of the data\n",
    "train_frames, train_labels = next(iter(train_ds))\n",
    "print(f'Shape of training set of frames: {train_frames.shape}')\n",
    "print(f'Shape of training labels: {train_labels.shape}')\n",
    "\n",
    "val_frames, val_labels = next(iter(val_ds))\n",
    "print(f'Shape of validation set of frames: {val_frames.shape}')\n",
    "print(f'Shape of validation labels: {val_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7091491b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.batch(2)\n",
    "val_ds = val_ds.batch(2)\n",
    "\n",
    "train_frames, train_labels = next(iter(train_ds))\n",
    "print(f'Shape of training set of frames: {train_frames.shape}')\n",
    "print(f'Shape of training labels: {train_labels.shape}')\n",
    "\n",
    "val_frames, val_labels = next(iter(val_ds))\n",
    "print(f'Shape of validation set of frames: {val_frames.shape}')\n",
    "print(f'Shape of validation labels: {val_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf8c618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9650b04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c66a3ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a975088-42af-4723-acca-75a8e8fabd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Átalakítás numpy tömbökké\n",
    "train_images = np.array(train_images) / 255.0  # Normalizálás\n",
    "test_images = np.array(test_images) / 255.0\n",
    "\n",
    "train_labels = to_categorical(train_labels, num_classes)  # One-hot encoding\n",
    "test_labels = to_categorical(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0785190",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff0df3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: CPU\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, make_scorer, mean_squared_log_error, \\\n",
    "    root_mean_squared_error\n",
    "\n",
    "# Neural Network with TensorFlow\n",
    "\n",
    "device = \"GPU\" if tf.config.list_physical_devices('GPU') else \"CPU\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 256\n",
    "\n",
    "activation_func = 'relu'\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 550:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * np.exp(-0.1)\n",
    "\n",
    "num_epochs = 50\n",
    "learning_rate = 1.5e-4\n",
    "criterion = tf.keras.losses.MeanSquaredError()\n",
    "# criterion = tf.keras.losses.MeanAbsoluteError()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=1e-5)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((tf.convert_to_tensor(train_images, dtype=tf.float32),\n",
    "                                                    tf.convert_to_tensor(train_labels, dtype=tf.float32)))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((tf.convert_to_tensor(test_images, dtype=tf.float32),\n",
    "                                                    tf.convert_to_tensor(test_labels, dtype=tf.float32)))\n",
    "\n",
    "train_loader = train_dataset.batch(batch_size, drop_remainder=True) # .shuffle(buffer_size=len(train_images))\n",
    "val_loader = val_dataset.batch(batch_size, drop_remainder=True) # .shuffle(buffer_size=len(test_images))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047c037b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.input_layer = tf.keras.layers.Dense((IMG_SIZE, IMG_SIZE, batch_size), activation=activation_func)\n",
    "\n",
    "        # self.feature_extractor = []\n",
    "        # for i in range(5):\n",
    "        #     self.hidden_layers.append(tf.keras.layers.Dense(2048, activation=activation_func))\n",
    "        #     self.hidden_layers.append(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "        self.hidden_layers = []\n",
    "        for i in range(7):\n",
    "            self.hidden_layers.append(tf.keras.layers.Dense(512, activation=activation_func))\n",
    "            self.hidden_layers.append(tf.keras.layers.Dropout(0.2))\n",
    "            self.hidden_layers.append(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "        # self.additional_layers = []\n",
    "        # for i in range(2):\n",
    "        #     self.additional_layers.append(tf.keras.layers.Dense(256, activation=activation_func))\n",
    "        #     self.additional_layers.append(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "        self.output_layer = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        # for layer in self.feature_extractor:\n",
    "        #     x = layer(x)\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        # for layer in self.additional_layers:\n",
    "        #     x = layer(x)\n",
    "\n",
    "        return self.output_layer(x)\n",
    "    \n",
    "\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7833373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Net.call().\n\n\u001b[1mInvalid dtype: tuple\u001b[0m\n\nArguments received by Net.call():\n  • x=tf.Tensor(shape=(256, 32, 32, 3), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, (batch_x, batch_y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m---> 13\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(batch_y, tf\u001b[38;5;241m.\u001b[39msqueeze(outputs))\n\u001b[0;32m     16\u001b[0m     grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, model\u001b[38;5;241m.\u001b[39mtrainable_weights)\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[1;32mIn[28], line 60\u001b[0m, in \u001b[0;36mNet.call\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 60\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# for layer in self.feature_extractor:\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m#     x = layer(x)\u001b[39;00m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_layers:\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling Net.call().\n\n\u001b[1mInvalid dtype: tuple\u001b[0m\n\nArguments received by Net.call():\n  • x=tf.Tensor(shape=(256, 32, 32, 3), dtype=float32)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "    train_loss = 0\n",
    "    for step, (batch_x, batch_y) in enumerate(train_loader):\n",
    "        with tf.GradientTape() as tape:\n",
    "            outputs = model(batch_x, training=True)\n",
    "            loss = criterion(batch_y, tf.squeeze(outputs))\n",
    "\n",
    "        grads = tape.gradient(loss, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "        train_loss += loss.numpy()\n",
    "\n",
    "    train_losses.append(train_loss / len(train_loader))\n",
    "\n",
    "    # Validation loop\n",
    "    val_loss = 0\n",
    "    for batch_x, batch_y in val_loader:\n",
    "        outputs = model(batch_x, training=False)\n",
    "        loss = criterion(batch_y, tf.squeeze(outputs))\n",
    "        val_loss += loss.numpy()\n",
    "\n",
    "    val_losses.append(val_loss / len(val_loader))\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch + 1}/{num_epochs}, \"\n",
    "        f\"Train Loss: {train_loss / len(train_loader):.4f}, \"\n",
    "        f\"Validation Loss: {val_loss / len(val_loader):.4f}\"\n",
    "    )\n",
    "\n",
    "train_losses = np.array(train_losses)\n",
    "val_losses = np.array(val_losses)\n",
    "\n",
    "# Making predictions\n",
    "x_train_tensor = tf.convert_to_tensor(train_dataset, dtype=tf.float32)\n",
    "x_test_tensor = tf.convert_to_tensor(val_dataset, dtype=tf.float32)\n",
    "\n",
    "y_train_pred = model(x_train_tensor, training=False).numpy()\n",
    "y_test_pred = model(x_test_tensor, training=False).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfdbf7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r2_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_r2 \u001b[38;5;241m=\u001b[39m \u001b[43mr2_score\u001b[49m(y_train, y_train_pred)\n\u001b[0;32m      2\u001b[0m test_r2 \u001b[38;5;241m=\u001b[39m r2_score(y_test, y_test_pred)\n\u001b[0;32m      3\u001b[0m test_mse \u001b[38;5;241m=\u001b[39m mean_squared_error(y_test, y_test_pred)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'r2_score' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "print(f'Train R-squared: {train_r2 * 100:.2f}%')\n",
    "print(f'Test R-squared: {test_r2 * 100:.2f}%')\n",
    "print(f'Test Mean Squared Error (MSE): {test_mse:.2f}')\n",
    "print(f'Test Root Mean Squared Error (RMSE): {test_rmse:.2f}')\n",
    "print(f'Test Mean Absolute Error (MAE): {test_mae:.2f}')\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(y_test, label='Actual', marker='o', linestyle='None')\n",
    "plt.plot(y_test_pred, label='Predicted', marker='x', linestyle='None')\n",
    "plt.legend()\n",
    "plt.xlabel('Sample index')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Actual vs Predicted Values')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    "\n",
    "print(model.summary())\n",
    "print(model.get_config())\n",
    "print(optimizer.get_config())\n",
    "\n",
    "model.save(\"HousePrices/saved_models/nn_model_\" + exp_name + \".tf\",\n",
    "            save_format='tf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
